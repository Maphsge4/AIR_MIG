=> model params: 124439808
Test: [   0/1000]	Time  0.739 ( 0.739)
595184640
Test: [  10/1000]	Time  0.552 ( 0.572)
595184640
Test: [  20/1000]	Time  0.552 ( 0.565)
595184640

-------------------------- DeepSpeed Flops Profiler --------------------------
Profile Summary at step 30:
Notations:
data parallel size (dp_size), model parallel size(mp_size),
number of parameters (params), number of multiply-accumulate operations(MACs),
number of floating-point operations (flops), floating-point operations per second (FLOPS),
fwd latency (forward propagation latency), bwd latency (backward propagation latency),
step (weights update latency), iter latency (sum of fwd, bwd and step latency)

params per gpu:                                               124.44 M
params of model = params per GPU * mp_size:                   124.44 M
fwd MACs per GPU:                                             1546.19 GMACs
fwd flops per GPU:                                            3095.16 G
fwd flops of model = fwd flops per GPU * mp_size:             3095.16 G
fwd latency:                                                  846.94 ms
fwd FLOPS per GPU = fwd flops per GPU / fwd latency:          3.65 TFLOPS

----------------------------- Aggregated Profile per GPU -----------------------------
Top 1 modules in terms of params, MACs or fwd latency at different model depths:
depth 0:
    params      - {'GPT2Model': '124.44 M'}
    MACs        - {'GPT2Model': '1546.19 GMACs'}
    fwd latency - {'GPT2Model': '846.94 ms'}
depth 1:
    params      - {'ModuleList': '85.05 M'}
    MACs        - {'ModuleList': '1546.19 GMACs'}
    fwd latency - {'ModuleList': '805.28 ms'}
depth 2:
    params      - {'GPT2Block': '85.05 M'}
    MACs        - {'GPT2Block': '1546.19 GMACs'}
    fwd latency - {'GPT2Block': '805.28 ms'}
depth 3:
    params      - {'GPT2MLP': '56.67 M'}
    MACs        - {'GPT2MLP': '927.71 GMACs'}
    fwd latency - {'GPT2MLP': '373.37 ms'}

------------------------------ Detailed Profile per GPU ------------------------------
Each module profile is listed after its name in the following order: 
params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS

Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.
2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.
3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.

GPT2Model(
  124.44 M, 100.00% Params, 1546.19 GMACs, 100.00% MACs, 846.94 ms, 100.00% latency, 3.65 TFLOPS, 
  (wte): Embedding(38.6 M, 31.02% Params, 0 MACs, 0.00% MACs, 176.13 us, 0.02% latency, 0.0 FLOPS, 50257, 768)
  (wpe): Embedding(786.43 k, 0.63% Params, 0 MACs, 0.00% MACs, 16.38 us, 0.00% latency, 0.0 FLOPS, 1024, 768)
  (drop): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
  (h): ModuleList(
    (0): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.11 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.85 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.68 ms, 0.43% latency, 5.25 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.11 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.32 ms, 1.10% latency, 8.3 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.08 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.87 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.28 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.08 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.29 ms, 1.10% latency, 8.32 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.42 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.07 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 97.28 us, 0.01% latency, 646.74 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.84 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.28 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.23 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.1 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.79% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.3 ms, 1.10% latency, 8.31 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.43 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.13 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.85 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.68 ms, 0.43% latency, 5.25 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.14 ms, 3.68% latency, 4.96 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.36 ms, 1.11% latency, 8.26 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.18 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.85 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.2 ms, 3.68% latency, 4.96 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.41 ms, 1.11% latency, 8.21 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.4 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.08 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.08 ms, 3.67% latency, 4.98 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.79% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.31 ms, 1.10% latency, 8.31 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.4 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (6): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.14 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.15 ms, 3.68% latency, 4.96 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.36 ms, 1.10% latency, 8.26 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.42 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (7): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.11 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 93.18 us, 0.01% latency, 675.16 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.11 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.79% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.31 ms, 1.10% latency, 8.3 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (8): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.11 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.11 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.32 ms, 1.10% latency, 8.29 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.42 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (9): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.13 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.28 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.68 ms, 0.43% latency, 5.25 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.13 ms, 3.68% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.64 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.39 ms, 1.11% latency, 8.23 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.37 ms, 0.63% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (10): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.08 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.09 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.3 ms, 1.10% latency, 8.31 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (11): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.06 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.06 ms, 3.67% latency, 4.98 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.64 ms, 0.78% latency, 11.64 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.32 ms, 1.10% latency, 8.3 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.38 ms, 0.63% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
  )
  (ln_f): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
  (layers): ModuleList(
    (0): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.11 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.85 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.68 ms, 0.43% latency, 5.25 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.11 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.32 ms, 1.10% latency, 8.3 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (1): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.08 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.87 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.28 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.08 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.29 ms, 1.10% latency, 8.32 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.42 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (2): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.07 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 97.28 us, 0.01% latency, 646.74 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.84 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.28 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.23 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.1 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.79% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.3 ms, 1.10% latency, 8.31 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.43 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (3): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.13 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.85 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.68 ms, 0.43% latency, 5.25 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.14 ms, 3.68% latency, 4.96 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.36 ms, 1.11% latency, 8.26 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (4): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.18 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.85 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.2 ms, 3.68% latency, 4.96 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.41 ms, 1.11% latency, 8.21 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.4 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (5): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.08 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.08 ms, 3.67% latency, 4.98 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.79% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.31 ms, 1.10% latency, 8.31 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.4 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (6): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.14 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.15 ms, 3.68% latency, 4.96 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.36 ms, 1.10% latency, 8.26 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.42 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (7): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.11 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 93.18 us, 0.01% latency, 675.16 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.11 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.79% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.31 ms, 1.10% latency, 8.3 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (8): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.11 ms, 7.92% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.11 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.32 ms, 1.10% latency, 8.29 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.42 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (9): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.13 ms, 7.93% latency, 3.84 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.64 ms, 0.67% latency, 10.28 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.68 ms, 0.43% latency, 5.25 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.13 ms, 3.68% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.64 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.39 ms, 1.11% latency, 8.23 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.37 ms, 0.63% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (10): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.08 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 96.26 us, 0.01% latency, 653.62 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.09 ms, 3.67% latency, 4.97 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.65 ms, 0.78% latency, 11.63 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.3 ms, 1.10% latency, 8.31 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.41 ms, 0.64% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 3.07 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
    (11): GPT2Block(
      7.09 M, 5.70% Params, 128.85 GMACs, 8.33% MACs, 67.06 ms, 7.92% latency, 3.85 TFLOPS, 
      (ln_1): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 95.23 us, 0.01% latency, 660.65 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (attn): GPT2Attention(
        2.36 M, 1.90% Params, 51.54 GMACs, 3.33% MACs, 25.86 ms, 3.05% latency, 3.99 TFLOPS, 
        (c_attn): Conv1D(1.77 M, 1.42% Params, 28.99 GMACs, 1.88% MACs, 5.63 ms, 0.67% latency, 10.29 TFLOPS, )
        (c_proj): Conv1D(590.59 k, 0.47% Params, 9.66 GMACs, 0.62% MACs, 3.69 ms, 0.44% latency, 5.24 TFLOPS, )
        (attn_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
        (resid_dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
      (ln_2): LayerNorm(1.54 k, 0.00% Params, 0 MACs, 0.00% MACs, 94.21 us, 0.01% latency, 667.83 GFLOPS, (768,), eps=1e-05, elementwise_affine=True)
      (mlp): GPT2MLP(
        4.72 M, 3.79% Params, 77.31 GMACs, 5.00% MACs, 31.06 ms, 3.67% latency, 4.98 TFLOPS, 
        (c_fc): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 6.64 ms, 0.78% latency, 11.64 TFLOPS, )
        (c_proj): Conv1D(2.36 M, 1.90% Params, 38.65 GMACs, 2.50% MACs, 9.32 ms, 1.10% latency, 8.3 TFLOPS, )
        (act): NewGELUActivation(0, 0.00% Params, 0 MACs, 0.00% MACs, 5.38 ms, 0.63% latency, 0.0 FLOPS, )
        (dropout): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 4.1 us, 0.00% latency, 0.0 FLOPS, p=0.1, inplace=False)
      )
    )
  )
)
------------------------------------------------------------------------------
Test: [  30/1000]	Time  0.892 ( 0.574)
595184640
